# 2章 識別規則と学習法の概要

下記について、さらっと触れる章です

- データを学習する方法の種類（データの表現方法）
- 学習結果の評価方法
- 学習モデルの評価方法

---

## 2.1 識別規則と学習法の分類

識別規則 #とは

**入力データ $x$ からクラス $C_i$ への写像のこと。**

---

### 2.1.1 本書で解説する識別規則の構成方法


<img src="https://raw.githubusercontent.com/sunpot/essential-pattern-recognition/master/section-2/fig2-0-1.jpg" width="90%;">

- (a)事後確率による方法(代表例: ベイズの最大事後確率法)
　パターン空間に確率分布を仮定し、事後確率が最大のクラスに分類する。事後確率に関しては後章で解説。
- (b)距離による方法(代表例:最近傍法)
　入力ベクトルxxと各クラスの代表ベクトルとの距離を測定し、最も近い代表ベクトルクラスに分類する

---

### 2.1.1 本書で解説する識別規則の構成方法


<img src="https://raw.githubusercontent.com/sunpot/essential-pattern-recognition/master/section-2/fig2-0-2.jpg" width="90%;">

- (c)関数値による方法(代表例:サポートベクトルマシン)
　f(x)f(x)の正負あるいは最大値でクラスを決める。識別のために用いられるf(x)f(x)を識別関数と呼ぶ。
- (d)决定木による方法
　識別規則の真偽を順次適応し、決定木の形でクラスを決める。

---

### 2.1.2 教師付き学習

* 入力データの集合からある関数へ写像する
* **識別規則 = 求められた関数** のこと 
* 2クラスの場合  
$$ y = f(\vec{x}; \vec{w}) = x_1w_1  + ... + x_dw_d = \bold{w^Tx} $$

---

### 教師付き学習の進むイメージ

![](https://raw.githubusercontent.com/sunpot/essential-pattern-recognition/master/section-2/fig2-1.jpg)

---

### 2.1.3 教室付き学習と線形回帰

教師付き学習では... 
- 教師データをもとに関数のパラメータを最適化する

$$ x_i \to f(x_i) \to y_i$$

- ここでいう関数 = 線形関数
- 線形関数にフィッティングする ＝ 線形回帰

教師付き学習　線形回帰

--- 

### 2.1.4 教師なし学習

- 一定の基準を元にデータを自動的にクラスタ分けする
- 形式導入学習（？）

---

## 2.2 汎化能力

- 教師データだけに最適化されてはダメ
- **未知のデータも精度よく識別できる = 汎化能力が高い**

【目的】
集めたデータで適切に学習・評価して、汎化能力をあげよう！

1. 適切なサンプルデータの用意の仕方と評価方法
2. 適切なモデルの選択と評価

---

### 2.2.1 学習データとテストデータの作り方

たくさんの硬貨からデータを作る場合を考えます

<img src="https://raw.githubusercontent.com/sunpot/essential-pattern-recognition/master/section-2/fig2-2.jpg" width="600px;">

【前提】
- 誤り率: $\epsilon(p_L, p_T)$
- **再代入誤り率**: $\epsilon(p_L, p_L) = a$

---

### データ分割手法の例

1. ホールドアウト法
2. 交差確認法
3. 一つ抜き法
4. ブートストラップ法

---

### 1. ホールドアウト法

- 手元のデータを 8:2 などの割合で分割
- 片方を学習用、残りをテスト用に用いる

ホールドアウト誤り率を$\epsilon(p_L, p_T)$とすると、再代入誤り率との間には下記が成り立つ。
$$E_{D_L} \leq E_{D_T} $$

- 学習精度と性能評価の精度がトレードオフの関係
	- 学習データ多 -> 学習精度向上 : 性能評価悪化
	- テストデータ多 -> 学習精度悪化 : 性能評価向上

**大量のデータがない場合、学習精度と性能評価の精度を両立できない。**

---

### 2. 交差確認法 (Cross Validation: CV法)

<div style="overflow: hidden;">
  <div style="float: left;width: 50%">
    <br>
    <br>
    <ul>
      <li>データセットをm個に分割</li>
      <li>m-1個で学習し、残りでテスト</li>
      <li>m回繰り返す</li>
    </ul>
    <p>分割の大きさなどによって偏りが生じるため、いくつかのパターンで分割を行い、平均値を評価する。</p>
  </div>
  <div>
    <img src="https://raw.githubusercontent.com/sunpot/essential-pattern-recognition/master/section-2/fig2-3.jpg" width="50%;">
  </div>
</div>

---

### 3. 一つ抜き法

CV法で
	データ数 = 分割数m  
    の場合を指す。
    
---

### 4. ブートストラップ法

再代入誤り率の補正をするための手法

- 重複を許容するサンプリングを複数回行う
  ```
  raw data: |abcd|
  sample1:  |bacc|
  sample2:  |dabc|
  ...
  ```
- 下記でバイアスの予測値を得る
$$ bias = \epsilon(D, D_L) - \epsilon(D_L, D_L) $$
- 得られたバイアス予測値を元に補正をし、真の誤り率を求める
$$ \epsilon = \epsilon(D, D) + \bar{bias} $$

---

### 4. ブートストラップ法 (概念)

![図](https://camo.qiitausercontent.com/1f0e19a14c66a6a424b2fc3fdfba37814c9f6175/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f36373231372f33356365636662352d643865342d386661652d316333372d6230343633633539326431622e706e67)

[機械学習の性能を正しく評価するための検証手法](https://qiita.com/sergeant-wizard/items/29868c768faa3e7e7f6d)

---

### 2.2.2 汎化能力の評価方法とモデル選択

- モデルではサンプルで良い結果が出た！
- 実際に予測させてみると…全然ダメだ！
- 正しい予測をするにはどのようなモデル ( $f(x)$ ) を使えばいい？

---

### モデルの評価方法

- サンプルとモデルの間の二乗平均誤差（Mean Square Error: MSE）で評価できる

1. 複数のデータセットに対してMSEを算出
2. MSEのばらつき（分散）を評価
3. MSEそのものが小さく、かつMSEの分散も小さければ○

---

### 多項式をモデルとした場合

<img src="https://raw.githubusercontent.com/sunpot/essential-pattern-recognition/master/section-2/fig2-4.jpg" width="90%;">

- 次数が低すぎるとMSEのばらつきは小さくなる
- 次数が高すぎるとよくフィットするが、MSEのばらつきが大きい

<p align=center>モデルのばらつきが小さい: 高バイアス</p>
<p align=center>モデルのばらつきが大きい: 高バリアンス</p>

<p align=center>両者はトレードオフの関係（バイアス・バリアンストレードオフ）</p>

---

### 多項式モデルの次数と検証結果の関係

<img src="https://raw.githubusercontent.com/sunpot/essential-pattern-recognition/master/section-2/fig2-5.jpg" width="90%;">

---

## 章末問題

1. ブートストラップ法で再代入誤り率バイアスを推定する際、サンプルされたデータで設計し、サンプルされなかったデータでテストした誤り率の平均で求めた場合の問題点は何か。

同じデータ集合の中で意図的にデータを重複させてサンプルすることで、バイアス値を推定することができる。サンプルされていないデータから推定すると、真のバイアス値から外れた値を推定してしまう。

## 章末問題

2. 式2.4から式2.5を求めよ